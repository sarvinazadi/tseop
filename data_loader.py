#data_loader.py
import pandas as pd
import numpy as np
import pytse_client as tse
import os
import pickle

def fetch_and_clean_data(tickers, save_path="clean_market_data.pkl", force_update=False):
    """
    Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¯Ø³ØªÙ‡â€ŒØ¬Ù…Ø¹ÛŒ (Batch) Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ø¨Ø§Ú¯ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡.
    """
    
    # 1. Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ù‡Ø³Øª Ùˆ Ø§Ø¬Ø¨Ø§Ø± Ø¨Ù‡ Ø¢Ù¾Ø¯ÛŒØª Ù†Ø¯Ø§Ø±ÛŒÙ…ØŒ Ù„ÙˆØ¯ Ú©Ù†
    if os.path.exists(save_path) and not force_update:
        print(f"ğŸ“‚ Loading existing data from {save_path}...")
        with open(save_path, 'rb') as f:
            return pickle.load(f)

    print(f"â³ Starting BATCH download for {len(tickers)} tickers...")
    
    # 2. Ø¯Ø§Ù†Ù„ÙˆØ¯ ÛŒÚ©Ø¨Ø§Ø±Ù‡ (Batch Download) - Ø±ÙØ¹ Ø¨Ø§Ú¯ unhashable type
    try:
        # Ú©Ù„ Ù„ÛŒØ³Øª Ø±Ø§ ÛŒÚ©Ø¬Ø§ Ù…ÛŒâ€ŒØ¯Ù‡ÛŒÙ…. Ø®Ø±ÙˆØ¬ÛŒ ÛŒÚ© Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø§Ø³Øª: { 'namad': DataFrame, ... }
        raw_data_map = tse.download(tickers, write_to_csv=False, adjust=True)
    except Exception as e:
        print(f"âŒ Critical Error in Batch Download: {e}")
        return None, None

    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø¯ÛŒØªØ§ÛŒÛŒ Ø¢Ù…Ø¯ ÛŒØ§ Ù†Ù‡
    if not raw_data_map:
        print("âŒ No data received from TSE Client.")
        return None, None

    print(f"   âœ… Download successful. Received {len(raw_data_map)} tickers.")
    
    data_map = {}
    valid_tickers = []

    # 3. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø§ÙˆÙ„ÛŒÙ‡ Ø±ÙˆÛŒ Ù‡Ø± Ø³Ù‡Ù…
    for ticker in tickers:
        if ticker not in raw_data_map:
            print(f"   âš ï¸ Warning: Data for {ticker} not returned by server. Skipping.")
            continue
            
        df = raw_data_map[ticker]
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø®Ø§Ù„ÛŒ Ù†Ø¨ÙˆØ¯Ù†
        if df.empty:
            print(f"   âš ï¸ Warning: {ticker} has empty data. Skipping.")
            continue

        try:
            # Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Ø³Ø§Ø²ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
            df = df[['date', 'open', 'high', 'low', 'close', 'volume']]
            df['date'] = pd.to_datetime(df['date'])
            df = df.set_index('date')
            
            data_map[ticker] = df
            valid_tickers.append(ticker)
            # print(f"      -> {ticker}: {len(df)} days.")
        except KeyError as e:
            print(f"   âŒ Data format error for {ticker}: Missing column {e}")

    if not valid_tickers:
        print("âŒ No valid data available after processing.")
        return None, None

    # 4. Ù‡Ù…Ú¯Ø§Ù…â€ŒØ³Ø§Ø²ÛŒ Ø²Ù…Ø§Ù†ÛŒ (The Synchronization)
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®ÛŒ Ú©Ù‡ Ù‡Ù…Ù‡ Ø³Ù‡Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ø¯Ø± Ø¢Ù† Ø­Ø¶ÙˆØ± Ø¯Ø§Ø±Ù†Ø¯ (Ù…Ø§Ú©Ø³ÛŒÙ…Ù…Ù ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ÛŒ Ø´Ø±ÙˆØ¹)
    start_dates = [data_map[t].index.min() for t in valid_tickers]
    common_start_date = max(start_dates)
    
    end_dates = [data_map[t].index.max() for t in valid_tickers]
    common_end_date = min(end_dates)

    print(f"\nğŸ“… Synchronization Info:")
    print(f"   Common Start Date: {common_start_date.date()}")
    print(f"   Common End Date:   {common_end_date.date()}")
    
    if common_start_date >= common_end_date:
        print("âŒ Date overlap issue: Start date is after End date. Check your tickers list.")
        return None, None

    # ØªÙ‚ÙˆÛŒÙ… Ù…Ø±Ø¬Ø¹
    full_date_range = pd.date_range(start=common_start_date, end=common_end_date, freq='D')
    print(f"   Total Days: {len(full_date_range)}")

    # 5. Ø³Ø§Ø®Øª Ù…Ø§ØªØ±ÛŒØ³ Ù†Ù‡Ø§ÛŒÛŒ
    n_days = len(full_date_range)
    n_assets = len(valid_tickers)
    n_features = 5
    
    final_data = np.zeros((n_days, n_assets, n_features))
    
    print("\nğŸ”„ Filling Gaps (FFILL)...")
    for i, ticker in enumerate(valid_tickers):
        df = data_map[ticker]
        
        # Ø¨Ø§Ø²Ú†ÛŒÙ†ÛŒ Ùˆ Ù¾Ø± Ú©Ø±Ø¯Ù† Ø¬Ø§Ù‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ Ø¨Ø§ Ù‚ÛŒÙ…Øª Ø±ÙˆØ² Ù‚Ø¨Ù„
        df_reindexed = df.reindex(full_date_range)
        df_filled = df_reindexed.ffill() 
        df_filled = df_filled.bfill() # Ø¨Ø±Ø§ÛŒ Ù…Ø­Ú©Ù… Ú©Ø§Ø±ÛŒ Ø±ÙˆØ² Ø§ÙˆÙ„
        df_filled = df_filled.fillna(0) # Ù†Ø¨Ø§ÛŒØ¯ Ø§ØªÙØ§Ù‚ Ø¨ÛŒÙØªØ¯

        final_data[:, i, 0] = df_filled['open'].values
        final_data[:, i, 1] = df_filled['high'].values
        final_data[:, i, 2] = df_filled['low'].values
        final_data[:, i, 3] = df_filled['close'].values
        final_data[:, i, 4] = df_filled['volume'].values

    # 6. Ú†Ú© Ù†Ù‡Ø§ÛŒÛŒ
    if np.min(final_data[:, :, 3]) < 10.0:
        print("âš ï¸ Warning: Still found prices < 10.0. Inspect data carefully.")
    else:
        print("âœ… Data Integrity Check Passed (No zero prices).")

    final_dates = full_date_range.strftime("%Y-%m-%d").tolist()
    
    # Ø°Ø®ÛŒØ±Ù‡
    with open(save_path, 'wb') as f:
        pickle.dump((final_data, final_dates, valid_tickers), f) # valid_tickers Ø±Ø§ Ù‡Ù… Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        
    print(f"ğŸ’¾ Saved to {save_path}")
    
    # Ù†Ú©ØªÙ‡: Ø®Ø±ÙˆØ¬ÛŒ valid_tickers Ø±Ø§ Ù‡Ù… Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†ÛŒÙ… Ø´Ø§ÛŒØ¯ Ù„ÛŒØ³Øª Ø§ÙˆÙ„ÛŒÙ‡ ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡ Ø¨Ø§Ø´Ø¯
    return final_data, final_dates, valid_tickers

if __name__ == "__main__":
    # ØªØ³Øª
    my_tickers = ["ÙÙˆÙ„Ø§Ø¯", "Ø´Ù¾Ù†Ø§", "ÙˆØ¨Ù…Ù„Øª", "ÙÙ…Ù„ÛŒ", "Ø´Ø³ØªØ§", "Ø®ÙˆØ¯Ø±Ùˆ", "ÙˆØªØ¬Ø§Ø±Øª"]
    # my_tickers = ["ÙÙˆÙ„Ø§Ø¯", "Ø´Ù¾Ù†Ø§"] # ØªØ³Øª Ø¨Ø§ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù…
    d, dates, final_tickers = fetch_and_clean_data(my_tickers, force_update=True)
    
    if d is not None:
        print("Output Shape:", d.shape)
        print("Final Tickers:", final_tickers)
